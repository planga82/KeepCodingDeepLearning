{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of (S) 8. Aplicaciones.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"198N0SFL_yU8Dy__-3BxI9XidKEdSjWqw","timestamp":1529568297388}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"obXJtqvCUtRv","colab_type":"text"},"cell_type":"markdown","source":["# 8. Aplicaciones\n","\n","¡Bienvenidos a la octava y última sesión! Si habéis llegado hasta aquí, enhorabuena! Ya sois un@s cracks en Deep Learning!\n","\n","Por recapitular un poco, lo que hemos visto durante estas últimas 7 sesiones ha sido:\n","\n","- Qué son, como funcionan, y como implementar, entrenar y tunear redes neuronales\n","- Qué son, como funcionan, y como implementar, entrenar y tunear redes neuronales convolucionales\n","- Qué son, como funcionan, y como implementar, entrenar y tunear redes neuronales recurrentes\n","- Diferentes métodos de optimización de los hiperparámetros de estas redes\n","\n","Con toda esta formación deberíais ya ser capaces de implementar una solución a cualquier problema que os surja :) No sin antes por supuesto hacer unas cuantas búsquedas en Google, pero qué programador no tiene que buscar en google?\n","\n","Bueno, vamos a ver qué nos espera hoy. La sesión de hoy va a ser eminentemente práctica. En ella, vamos a implementar un ejemplo de segmentación, otro de SSD (Single Shot Detectors) y otro de Image Captioning, que será parecido a vuestra práctica final.\n","\n","A cada ejemplo le acompañará una pequeña explicación para que sepáis como funcionan, pero no vamos a entrar en detalle. Quien quiera, existen una barbaridad de material en internet donde podéis entender los entresijos de estas técnicas, y aquí no nos da tiempo. Por eso, he preferido que veáis varios ejemplos aunque no los explique en detalle, antes que ver solo uno en detalle.\n","\n","Así que vamos a ello:\n","\n","**Aplicaciones**\n","* Segmentación\n","* SSD\n","* Image captioning\n","\n"]},{"metadata":{"id":"dQJdg6vYYUFx","colab_type":"text"},"cell_type":"markdown","source":["## 8.1 Segmentación\n","\n","La primera aplicación real de hoy es la segmentación de imágenes con CNNs. Existen básicamente dos modos de hacerlo:\n","\n","* **Con Fully Convolutional Networks:**\n","\n","<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/Fully_Convolutional_Network_Semantic.PNG\" border=\"0\" width=\"600\">\n","\n","Estas redes tienen la arquitectura que tendría cualquier CNN, excepto que la última capa se sustituye por una capa convolusional con un \"receptive field\" más grande. De hecho, tan grande que pueda capturar la escena global de la imagen: que nos pueda decir qué es lo que hay en la imagen y una idea aproximada de donde están dichas cosas.\n","\n","<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/FCN.jpg\" border=\"0\" width=\"600\">\n","\n","* **Con \"Redes deconvolucionales\":\n","\n","Lo primero que tengo que deciros es que el nombre está mal puesto, porque lo que hacemos no es la de-convolución, que supongo que todos entenderéis como deshacer la convolución, si no que aplicamos una convolución transpuesta. Esto no tiene mayor importancia, pero por que lo sepáis.\n","\n","Básicamente lo que ocurre es esto:\n","\n","<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/Conv_Deconv.PNG\" border=\"0\" width=\"600\">\n","\n","Y aquí lo podéis ver con ejemplos reales:\n","\n","<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/Deconvnet.png\" border=\"0\" width=\"600\">\n","\n","\n","Y en la siguiente imagen podéis ver los resultados de los dos tipos:\n","\n","<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/DeconvnetResults.png\" border=\"0\" width=\"600\">\n","\n","El ejemplo que vamos a implementar nosotros lo tenéis disponible en 8. Ejemplo segmentación, y en él, usaremos las FCNs.\n","\n","Fuente: https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_segmentation.html\n","\n"]},{"metadata":{"id":"v2-c9uBSlH4G","colab_type":"text"},"cell_type":"markdown","source":["## 8.2 Single-Shot Detectors\n","\n","Este tipo de redes, además de detectar los objetos que aparecen en las imágenes, detectan dónde estan situados. El SSD proviene de técnicas previas: R-CNN, Fast-R-CNN y Faster-R-CNN, en las que podéis indagar si tenéis curiosidad. Básicamente, la R proviene de *Region based* CNN, y como podéis intuir, lo que hacen es dividir la imagen de entrada en diferentes regiones, y luego predecir lo que hay en esas regiones. De esta forma, son capces de dar una localización aproximada de los objetos (i.e. una bounding box).\n","\n","Los SSDs, cuyo paper escrito por Szegedy tenéis disponible aquí: https://arxiv.org/abs/1512.02325, consigue lo mismo solo que más rápido. En concreto, en solamente una pasada hacia delante (forward pass). Las técnicas que os he comentado antes, en cambio, necesitan varias pasadas.\n","\n","Vamos a ver su arquitectura:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/800/1*51joMGlhxvftTxGtA4lA7Q.png\" border=\"0\" width=\"600\">\n","\n","Si os fijáis, está basada en la arquitectura de la VGG16, descartando las últimas capas, las fully connected o densas. Y en vez de esas, le acoplan una serie de capas convolucionales que permiten extraer características a diferentes escalas e ir reduciendo el tamaño progresivamente en las siguientes capas.\n","\n","Recordad la arquitectura de la VGG16:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/800/1*51joMGlhxvftTxGtA4lA7Q.png\" border=\"0\" width=\"600\">\n","\n","Lo que hace después, es aplicar una técnica de bounding box regression (desaarrollada también por Szegedy), para quedarse con las mejores bounding boxes.\n","\n","Por último, aplica probabilidades y métricas (IntersectionOverUnion), como podéis ver aquí:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/800/1*_Xf5FUbuUgq8GNyITM3Dwg.png\" border=\"0\" width=\"400\">\n","\n","Y así, de modo resumido, esto es lo que hacen los SSDs.\n","\n","Podéis ver aquí un ejemplo de detección de vehículos en tiempo real:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/800/1*IZf0wajQ75DPsoBkWjwlsA.gif\" border=\"0\">\n","\n","Y sin más dilación, vamos a por nuestro ejemplo, que tenéis en el notebook 8.Single-Shot Detector. :D\n","\n","FUENTE: https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab"]},{"metadata":{"id":"LBfWCuoDRSDW","colab_type":"text"},"cell_type":"markdown","source":["## 8.3 Image captioning\n","\n","Esto es lo voy a explicar para facilitaros un poco el desarrollo de la práctica, ya que si no, os va a resultar muy cuesta arriba y vais a necesitar a nuestro amigo Google demasiado.\n","\n","Básicamente, lo que queremos es esto:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/1600/1*6BFOIdSHlk24Z3DFEakvnQ.png\" border=\"0\">\n","\n","Es decir, una red que nos pase de IMAGEN a DESCRIPCIÓN. Para ello, lo que necesitamos implementar es algo parecido a esto:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/1600/1*vzFwXFJOrg6WRGNsYYT6qg.png\">\n","\n","Que no es otra cosa que una CNN para extraer las características de la imagen, seguida de una LSTM que utiliza las características de la imagen (y la palabra predicha previamente) para predecir la siguiente palabra.\n","\n","Así que vamos a verlo! Lo tenéis disponible en el notebook 8. Image captioning.\n","\n","Aquí os dejo una lista de datasets que podéis utilizar:\n","\n","Datasets:\n","\n","* Common Objects in Context (COCO). 120000 imágenes con sus descripciones. http://mscoco.org/dataset/#overview\n","* Flickr 8K. 8000 imagenes con sus descripciones extraídas de flickr.com. http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html\n","* Flickr 30K. 30000 imagenes con sus descripciones extraídas de flickr.com. http://shannon.cs.illinois.edu/DenotationGraph/\n","* Exploring Image Captioning Datasets, 2016. http://sidgan.me/technical/2016/01/09/Exploring-Datasets"]},{"metadata":{"id":"fGPo7lz7X-FN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}